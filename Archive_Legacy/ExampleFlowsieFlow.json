{
  "nodes": [
    {
      "id": "startAgentflow_0",
      "type": "agentFlow",
      "position": {
        "x": -241.58365178492127,
        "y": 86.32546838777353
      },
      "data": {
        "id": "startAgentflow_0",
        "label": "Start",
        "version": 1.1,
        "name": "startAgentflow",
        "type": "Start",
        "color": "#7EE787",
        "hideInput": true,
        "baseClasses": [
          "Start"
        ],
        "category": "Agent Flows",
        "description": "Starting point of the agentflow",
        "inputParams": [
          {
            "label": "Input Type",
            "name": "startInputType",
            "type": "options",
            "options": [
              {
                "label": "Chat Input",
                "name": "chatInput",
                "description": "Start the conversation with chat input"
              },
              {
                "label": "Form Input",
                "name": "formInput",
                "description": "Start the workflow with form inputs"
              }
            ],
            "default": "chatInput",
            "id": "startAgentflow_0-input-startInputType-options",
            "display": true
          },
          {
            "label": "Form Title",
            "name": "formTitle",
            "type": "string",
            "placeholder": "Please Fill Out The Form",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formTitle-string",
            "display": true
          },
          {
            "label": "Form Description",
            "name": "formDescription",
            "type": "string",
            "placeholder": "Complete all fields below to continue",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formDescription-string",
            "display": true
          },
          {
            "label": "Form Input Types",
            "name": "formInputTypes",
            "description": "Specify the type of form input",
            "type": "array",
            "show": {
              "startInputType": "formInput"
            },
            "array": [
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Options",
                    "name": "options"
                  }
                ],
                "default": "string"
              },
              {
                "label": "Label",
                "name": "label",
                "type": "string",
                "placeholder": "Label for the input"
              },
              {
                "label": "Variable Name",
                "name": "name",
                "type": "string",
                "placeholder": "Variable name for the input (must be camel case)",
                "description": "Variable name must be camel case. For example: firstName, lastName, etc."
              },
              {
                "label": "Add Options",
                "name": "addOptions",
                "type": "array",
                "show": {
                  "formInputTypes[$index].type": "options"
                },
                "array": [
                  {
                    "label": "Option",
                    "name": "option",
                    "type": "string"
                  }
                ]
              }
            ],
            "id": "startAgentflow_0-input-formInputTypes-array",
            "display": true
          },
          {
            "label": "Ephemeral Memory",
            "name": "startEphemeralMemory",
            "type": "boolean",
            "description": "Start fresh for every execution without past chat history",
            "optional": true
          },
          {
            "label": "Flow State",
            "name": "startState",
            "description": "Runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string",
                "placeholder": "Foo"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "placeholder": "Bar"
              }
            ],
            "id": "startAgentflow_0-input-startState-array",
            "display": true
          },
          {
            "label": "Persist State",
            "name": "startPersistState",
            "type": "boolean",
            "description": "Persist the state in the same session",
            "optional": true,
            "id": "startAgentflow_0-input-startPersistState-boolean",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "startInputType": "formInput",
          "formTitle": "Biblical Forensic Analysis",
          "formDescription": "Provide details for analyzing survivor testimony for Biblical patterns",
          "formInputTypes": [
            {
              "type": "string",
              "label": "Query or Transcript",
              "name": "query"
            },
            {
              "type": "boolean",
              "label": "Anonymize",
              "name": "anonymize"
            },
            {
              "type": "options",
              "label": "Output Type",
              "name": "output_type",
              "addOptions": [
                {
                  "option": "summary"
                },
                {
                  "option": "study_guide"
                },
                {
                  "option": "timeline"
                },
                {
                  "option": "audio"
                }
              ]
            }
          ],
          "startState": [
            {
              "key": "subagents",
              "value": ""
            },
            {
              "key": "findings",
              "value": ""
            }
          ]
        },
        "outputAnchors": [
          {
            "id": "startAgentflow_0-output-startAgentflow",
            "label": "Start",
            "name": "startAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 103,
      "height": 66,
      "selected": false,
      "positionAbsolute": {
        "x": -241.58365178492127,
        "y": 86.32546838777353
      },
      "dragging": false
    },
    {
      "id": "chatLocalAI_0",
      "type": "chatLocalAI",
      "position": {
        "x": -150.0,
        "y": 200.0
      },
      "data": {
        "id": "chatLocalAI_0",
        "label": "ChatLocalAI",
        "version": 1,
        "name": "chatLocalAI",
        "type": "ChatLocalAI",
        "color": "#FF6347",
        "baseClasses": [
          "ChatLocalAI"
        ],
        "category": "Chat Models",
        "description": "Local AI model for processing queries",
        "inputParams": [
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "string",
            "default": "Qwen3-8B",
            "id": "chatLocalAI_0-input-modelName-string",
            "display": true
          },
          {
            "label": "API Endpoint",
            "name": "apiEndpoint",
            "type": "string",
            "default": "http://lm-studio:1234/v1",
            "id": "chatLocalAI_0-input-apiEndpoint-string",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "default": 0.7,
            "id": "chatLocalAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "default": 512,
            "id": "chatLocalAI_0-input-maxTokens-number",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "Qwen3-8B",
          "apiEndpoint": "http://lm-studio:1234/v1",
          "temperature": 0.7,
          "maxTokens": 512
        },
        "outputAnchors": [
          {
            "id": "chatLocalAI_0-output-chatLocalAI",
            "label": "ChatLocalAI",
            "name": "chatLocalAI"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 200,
      "height": 80,
      "selected": false,
      "positionAbsolute": {
        "x": -150.0,
        "y": 200.0
      },
      "dragging": false
    },
    {
      "id": "llmAgentflow_0",
      "position": {
        "x": -111.52635639216058,
        "y": 83.67035986437665
      },
      "data": {
        "id": "llmAgentflow_0",
        "label": "Planner",
        "version": 1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_0-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_0-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_0-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_0-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_0-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_0-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_0-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_0-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatLocalAI",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p>You are an expert research lead, focused on high-level research strategy, planning, efficient delegation to subagents, and final report writing. Your core goal is to be maximally helpful to the user by leading a process to research the user's query for Biblical forensic analysis, pattern recognition in survivor testimony, and corroboration with Biblical references. Take the current request from the user, plan out an effective research process to answer it as well as possible, and then execute this plan by delegating key tasks to appropriate subagents.</p><p>The current date is {{ current_date_time }}.</p><p><research_process>...</research_process><subagent_count_guidelines>...</subagent_count_guidelines><delegation_instructions>...</delegation_instructions><answer_formatting>...</answer_formatting><important_guidelines>...</important_guidelines>"
            },
            {
              "role": "user",
              "content": "<p>Query:</p><p>{{ $form.query }}</p><p>Anonymize: {{ $form.anonymize }}</p><p>Output Type: {{ $form.output_type }}</p>"
            }
          ],
          "llmEnableMemory": true,
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": [
            {
              "key": "subagents",
              "type": "jsonArray",
              "enumValues": "",
              "jsonSchema": "{\n  \"task\": {\n    \"type\": \"string\",\n    \"description\": \"The research task for subagent\"\n  }\n}",
              "description": "A list of subagents to perform research task"
            }
          ],
          "llmUpdateState": [
            {
              "key": "subagents",
              "value": "<p>{{ output.subagents }}</p>"
            }
          ],
          "llmModelConfig": {
            "credential": "",
            "modelName": "Qwen3-8B",
            "temperature": 0.7,
            "streaming": true,
            "maxTokensToSample": 512,
            "topP": "",
            "topK": "",
            "extendedThinking": "",
            "budgetTokens": 1024,
            "allowImageUploads": "",
            "llmModel": "chatLocalAI"
          },
          "llmUserMessage": ""
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_0-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 213,
      "height": 72,
      "selected": false,
      "positionAbsolute": {
        "x": -111.52635639216058,
        "y": 83.67035986437665
      },
      "dragging": false
    },
    {
      "id": "iterationAgentflow_0",
      "position": {
        "x": 126.70987564816664,
        "y": -5.337791594648138
      },
      "data": {
        "id": "iterationAgentflow_0",
        "label": "Spawn SubAgents",
        "version": 1,
        "name": "iterationAgentflow",
        "type": "Iteration",
        "color": "#9C89B8",
        "baseClasses": [
          "Iteration"
        ],
        "category": "Agent Flows",
        "description": "Execute the nodes within the iteration block through N iterations",
        "inputParams": [
          {
            "label": "Array Input",
            "name": "iterationInput",
            "type": "string",
            "description": "The input array to iterate over",
            "acceptVariable": true,
            "rows": 4,
            "id": "iterationAgentflow_0-input-iterationInput-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "iterationInput": "<p>{{ $flow.state.subagents }}</p>"
        },
        "outputAnchors": [
          {
            "id": "iterationAgentflow_0-output-iterationAgentflow",
            "label": "Iteration",
            "name": "iterationAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "iteration",
      "width": 300,
      "height": 250,
      "selected": false,
      "positionAbsolute": {
        "x": 126.70987564816664,
        "y": -5.337791594648138
      },
      "dragging": false
    },
    {
      "id": "agentAgentflow_0",
      "position": {
        "x": 53.64516693688461,
        "y": 77.49272566017132
      },
      "data": {
        "id": "agentAgentflow_0",
        "label": "SubAgent",
        "version": 1,
        "name": "agentAgentflow",
        "type": "Agent",
        "color": "#4DD0E1",
        "baseClasses": [
          "Agent"
        ],
        "category": "Agent Flows",
        "description": "Dynamically choose and utilize tools during runtime, enabling multi-step reasoning",
        "inputParams": [
          {
            "label": "Model",
            "name": "agentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "agentAgentflow_0-input-agentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "agentMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "agentAgentflow_0-input-agentMessages-array",
            "display": true
          },
          {
            "label": "Tools",
            "name": "agentTools",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Tool",
                "name": "agentSelectedTool",
                "type": "asyncOptions",
                "loadMethod": "listTools",
                "loadConfig": true
              },
              {
                "label": "Require Human Input",
                "name": "agentSelectedToolRequiresHumanInput",
                "type": "boolean",
                "optional": true
              }
            ],
            "id": "agentAgentflow_0-input-agentTools-array",
            "display": true
          },
          {
            "label": "Knowledge (Document Stores)",
            "name": "agentKnowledgeDocumentStores",
            "type": "array",
            "description": "Give your agent context about different document sources. Document stores must be upserted in advance.",
            "array": [
              {
                "label": "Document Store",
                "name": "documentStore",
                "type": "asyncOptions",
                "loadMethod": "listStores"
              },
              {
                "label": "Describe Knowledge",
                "name": "docStoreDescription",
                "type": "string",
                "generateDocStoreDescription": true,
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_0-input-agentKnowledgeDocumentStores-array",
            "display": true
          },
          {
            "label": "Knowledge (Vector Embeddings)",
            "name": "agentKnowledgeVSEmbeddings",
            "type": "array",
            "description": "Give your agent context about different document sources from existing vector stores and embeddings",
            "array": [
              {
                "label": "Vector Store",
                "name": "vectorStore",
                "type": "asyncOptions",
                "loadMethod": "listVectorStores",
                "loadConfig": true
              },
              {
                "label": "Embedding Model",
                "name": "embeddingModel",
                "type": "asyncOptions",
                "loadMethod": "listEmbeddings",
                "loadConfig": true
              },
              {
                "label": "Knowledge Name",
                "name": "knowledgeName",
                "type": "string",
                "placeholder": "A short name for the knowledge base, this is useful for the AI to know when and how to search for correct information"
              },
              {
                "label": "Describe Knowledge",
                "name": "knowledgeDescription",
                "type": "string",
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_0-input-agentKnowledgeVSEmbeddings-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "agentEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "agentAgentflow_0-input-agentEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "agentMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_0-input-agentMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "agentMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "agentMemoryType": "windowSize"
            },
            "id": "agentAgentflow_0-input-agentMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "agentMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "agentMemoryType": "conversationSummaryBuffer"
            },
            "id": "agentAgentflow_0-input-agentMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "agentUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_0-input-agentUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "agentReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "agentAgentflow_0-input-agentReturnResponseAs-options",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "agentUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "agentAgentflow_0-input-agentUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "agentModel": "chatLocalAI",
          "agentMessages": [
            {
              "role": "system",
              "content": "<p>You are a research subagent working as part of a team for Biblical forensic analysis. The current date is {{ current_date_time }}. You have been given a clear <task> provided by a lead agent, and should use your available tools to accomplish this task in a research process, focusing on pattern recognition in survivor testimony and corroboration with Biblical references. Follow the instructions below closely to accomplish your specific <task> well:</p><p><task>{{ $iteration.task }}</task><research_process>...</research_process><research_guidelines>...</research_guidelines><think_about_source_quality>...</think_about_source_quality><use_parallel_tool_calls>...</use_parallel_tool_calls><maximum_tool_call_limit>...</maximum_tool_call_limit><citations>...</citations>"
            },
            {
              "role": "user",
              "content": "<p>Research task:</p><p>{{ $iteration.task }}</p>"
            }
          ],
          "agentTools": [
            {
              "agentSelectedTool": "arxiv",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "arxivName": "arxiv_search",
                "arxivDescription": "Use this tool to search for academic papers on Arxiv. You can search by keywords, topics, authors, or specific Arxiv IDs. The tool can return either paper summaries or download and extract full paper content.",
                "topKResults": "3",
                "maxQueryLength": "300",
                "docContentCharsMax": "5000",
                "loadFullContent": true,
                "continueOnFailure": true,
                "legacyBuild": "",
                "agentSelectedTool": "arxiv"
              }
            },
            {
              "agentSelectedTool": "googleCustomSearch",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "credential": "",
                "agentSelectedTool": "googleCustomSearch"
              }
            },
            {
              "agentSelectedTool": "webScraperTool",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "scrapeMode": "recursive",
                "maxDepth": 1,
                "maxPages": "2",
                "timeoutS": 60,
                "description": "",
                "agentSelectedTool": "webScraperTool"
              }
            },
            {
              "agentSelectedTool": "pgVectorSearch",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "description": "Search for Biblical references in PostgreSQL vector database using Qwen3-0.6B embeddings",
                "vectorStore": "living_truth_biblical_db",
                "embeddingModel": "Qwen3-0.6B",
                "knowledgeName": "Biblical References",
                "knowledgeDescription": "Contains embeddings of Biblical texts for pattern matching and corroboration",
                "returnSourceDocuments": true
              }
            }
          ],
          "agentKnowledgeDocumentStores": "",
          "agentEnableMemory": true,
          "agentMemoryType": "allMessages",
          "agentUserMessage": "<p>Research task:</p><p>{{ $iteration.task }}</p>",
          "agentReturnResponseAs": "userMessage",
          "agentUpdateState": "",
          "agentModelConfig": {
            "credential": "",
            "modelName": "Qwen3-0.6B",
            "temperature": 0.7,
            "streaming": true,
            "maxTokensToSample": 512,
            "topP": "",
            "topK": "",
            "extendedThinking": "",
            "budgetTokens": 1024,
            "allowImageUploads": "",
            "agentModel": "chatLocalAI"
          }
        },
        "outputAnchors": [
          {
            "id": "agentAgentflow_0-output-agentAgentflow",
            "label": "Agent",
            "name": "agentAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "parentNode": "iterationAgentflow_0",
      "extent": "parent",
      "width": 213,
      "height": 100,
      "selected": false,
      "positionAbsolute": {
        "x": 180.35504258505125,
        "y": 72.15493406552318
      },
      "dragging": false
    },
    {
      "id": "agentAgentflow_1",
      "position": {
        "x": 457.5784259377066,
        "y": 83.96506302841382
      },
      "data": {
        "id": "agentAgentflow_1",
        "label": "Writer Agent",
        "version": 1,
        "name": "agentAgentflow",
        "type": "Agent",
        "color": "#4DD0E1",
        "baseClasses": [
          "Agent"
        ],
        "category": "Agent Flows",
        "description": "Dynamically choose and utilize tools during runtime, enabling multi-step reasoning",
        "inputParams": [
          {
            "label": "Model",
            "name": "agentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "agentAgentflow_1-input-agentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "agentMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "agentAgentflow_1-input-agentMessages-array",
            "display": true
          },
          {
            "label": "Tools",
            "name": "agentTools",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Tool",
                "name": "agentSelectedTool",
                "type": "asyncOptions",
                "loadMethod": "listTools",
                "loadConfig": true
              },
              {
                "label": "Require Human Input",
                "name": "agentSelectedToolRequiresHumanInput",
                "type": "boolean",
                "optional": true
              }
            ],
            "id": "agentAgentflow_1-input-agentTools-array",
            "display": true
          },
          {
            "label": "Knowledge (Document Stores)",
            "name": "agentKnowledgeDocumentStores",
            "type": "array",
            "description": "Give your agent context about different document sources. Document stores must be upserted in advance.",
            "array": [
              {
                "label": "Document Store",
                "name": "documentStore",
                "type": "asyncOptions",
                "loadMethod": "listStores"
              },
              {
                "label": "Describe Knowledge",
                "name": "docStoreDescription",
                "type": "string",
                "generateDocStoreDescription": true,
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_1-input-agentKnowledgeDocumentStores-array",
            "display": true
          },
          {
            "label": "Knowledge (Vector Embeddings)",
            "name": "agentKnowledgeVSEmbeddings",
            "type": "array",
            "description": "Give your agent context about different document sources from existing vector stores and embeddings",
            "array": [
              {
                "label": "Vector Store",
                "name": "vectorStore",
                "type": "asyncOptions",
                "loadMethod": "listVectorStores",
                "loadConfig": true
              },
              {
                "label": "Embedding Model",
                "name": "embeddingModel",
                "type": "asyncOptions",
                "loadMethod": "listEmbeddings",
                "loadConfig": true
              },
              {
                "label": "Knowledge Name",
                "name": "knowledgeName",
                "type": "string",
                "placeholder": "A short name for the knowledge base, this is useful for the AI to know when and how to search for correct information"
              },
              {
                "label": "Describe Knowledge",
                "name": "knowledgeDescription",
                "type": "string",
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_1-input-agentKnowledgeVSEmbeddings-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "agentEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "agentAgentflow_1-input-agentEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "agentMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_1-input-agentMemoryType-options",
            "display": false
          },
          {
            "label": "Window Size",
            "name": "agentMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "agentMemoryType": "windowSize"
            },
            "id": "agentAgentflow_1-input-agentMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "agentMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "agentMemoryType": "conversationSummaryBuffer"
            },
            "id": "agentAgentflow_1-input-agentMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "agentUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_1-input-agentUserMessage-string",
            "display": false
          },
          {
            "label": "Return Response As",
            "name": "agentReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "agentAgentflow_1-input-agentReturnResponseAs-options",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "agentUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "agentAgentflow_1-input-agentUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "agentModel": "chatLocalAI",
          "agentMessages": [
            {
              "role": "system",
              "content": "<p>You are an expert research writer tasked with generating a high-quality, long-form Markdown report based on raw research findings for Biblical forensic analysis. Your primary responsibility is to transform complex, fragmented, or unstructured research inputs into a coherent, professional report that fully answers the user's original query, incorporating pattern recognition in survivor testimony and corroboration with Biblical references. This report should be suitable for an audience seeking a deep understanding of the subject.</p><p>Your guiding principles:<ol><li><strong>Preserve Full Context</strong><br>Include all relevant findings, explanations, and perspectives from the original materials. Do not omit, summarize, or oversimplify key information. Your job is to retain depth and nuance while improving structure and clarity.</li><li><strong>Maintain Citation Integrity</strong><br>Ensure all citations and source links from the original findings are accurately preserved in the final report. Do not invent, remove, or alter sources. If citations are embedded inline in the source findings, carry them forward appropriately.</li><li><strong>Add Structure and Clarity</strong><br>Organize the content into a well-structured Markdown format. Use clear section headings, bullet points, numbered lists, tables, and formatting as needed to improve readability and flow. Start with Introduction, end with Conclusion, and lastly sources.</li><li><strong>Markdown Output Only</strong><br>Your final output must be in Markdown format. Do not include explanations, side notes, or appendices. The only output should be the fully composed report ready for submission.</li></ol><p>Writing guidelines:<ol><li>Title: A clear, compelling title for the report that reflects the core subject.</li><li>Abstract/Executive Summary: A concise overview (approx. 200-300 words) of the report's main arguments, scope, and conclusions, derived from the conversation.</li><li>Introduction:<ul><li>Clearly define the central problem, question, or theme that the report will address</li><li>Outline the report's structure and objectives.</li></ul></li><li>Main Body / Thematic Analysis (Multiple Sections):<ul><li>Deconstruct and Synthesize Key Arguments: Detail the principal arguments, propositions, and evidence presented by all findings. Go beyond mere listing; analyze the strengths, weaknesses, and underlying assumptions of their positions.</li><li>Explore Core Themes and Concepts: Identify and elaborate on the major themes and concepts that emerged.</li><li>Analyze the Evolution of the Discussion: Trace how the understanding of the subject evolved throughout the findings. Highlight any shifts in perspective, critical turning points, challenged assumptions, or moments of significant clarification.</li><li>Evidence and Examples: Where the findings provided examples or evidence, incorporate and potentially expand upon these to support the report's analysis.</li></ul></li><li>Synthesis of Insights and Key Conclusions:<ul><li>Draw together the most significant insights and conclusions that can be derived from the entirety of the conversation.</li><li>This section should offer a consolidated understanding of the subject.</li></ul></li><li>Implications and Future Directions:<ul><li>Discuss the broader implications of the insights and conclusions reached.</li><li>Identify any unresolved questions, ambiguities, or areas that the conversation indicated require further exploration or research.</li><li>Suggest potential next steps or future avenues of inquiry.</li></ul></li><li>Conclusion: A strong concluding section summarizing the report's main findings, their significance, and a final thought on the subject.</li></ol><p>Style and Tone:<ul><li>Extensive and In-depth: The paper should be thorough and detailed.</li><li>Well-Structured: Use clear headings, subheadings, and logical flow.</li><li>Analytical and Critical: Do not just report; analyze, interpret, and critically engage with the ideas.</li><li>Objective and Authoritative: The report should present a balanced and well-reasoned perspective.</li><li>Formal and Professional Language: Maintain a tone appropriate for the report.</li></ul><p>Adapt the report to focus on Biblical forensic analysis, including pattern recognition, survivor testimony corroboration, and structured outputs based on user selection (summary, study_guide, timeline, audio).</p>"
            },
            {
              "role": "user",
              "content": "<p><research_topic>{{ $form.query }}</research_topic><existing_findings>{{ $flow.state.findings }}</existing_findings><new_findings>{{ iterationAgentflow_0 }}</new_findings><anonymize>{{ $form.anonymize }}</anonymize><output_type>{{ $form.output_type }}</output_type></p>"
            }
          ],
          "agentTools": "",
          "agentKnowledgeDocumentStores": "",
          "agentEnableMemory": false,
          "agentReturnResponseAs": "userMessage",
          "agentUpdateState": [
            {
              "key": "findings",
              "value": "<p>{{ output }}</p>"
            }
          ],
          "agentModelConfig": {
            "credential": "",
            "modelName": "Qwen3-8B",
            "temperature": 0.7,
            "streaming": true,
            "maxTokensToSample": 512,
            "topP": "",
            "topK": "",
            "extendedThinking": "",
            "budgetTokens": 1024,
            "allowImageUploads": "",
            "agentModel": "chatLocalAI"
          }
        },
        "outputAnchors": [
          {
            "id": "agentAgentflow_1-output-agentAgentflow",
            "label": "Agent",
            "name": "agentAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 284,
      "height": 72,
      "selected": false,
      "positionAbsolute": {
        "x": 457.5784259377066,
        "y": 83.96506302841382
      },
      "dragging": false
    },
    {
      "id": "conditionAgentAgentflow_0",
      "position": {
        "x": 775.5108094609307,
        "y": 79.60273632963377
      },
      "data": {
        "id": "conditionAgentAgentflow_0",
        "label": "More SubAgents?",
        "version": 1.1,
        "name": "conditionAgentAgentflow",
        "type": "ConditionAgent",
        "color": "#ff8fab",
        "baseClasses": [
          "ConditionAgent"
        ],
        "category": "Agent Flows",
        "description": "Utilize an agent to split flows based on dynamic conditions",
        "inputParams": [
          {
            "label": "Model",
            "name": "conditionAgentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "conditionAgentAgentflow_0-input-conditionAgentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Instructions",
            "name": "conditionAgentInstructions",
            "type": "string",
            "description": "A general instructions of what the condition agent should do",
            "rows": 4,
            "acceptVariable": true,
            "placeholder": "Determine if the user is interested in learning about AI",
            "id": "conditionAgentAgentflow_0-input-conditionAgentInstructions-string",
            "display": true
          },
          {
            "label": "Input",
            "name": "conditionAgentInput",
            "type": "string",
            "description": "Input to be used for the condition agent",
            "rows": 4,
            "acceptVariable": true,
            "default": "<p>{{ question }}</p>",
            "id": "conditionAgentAgentflow_0-input-conditionAgentInput-string",
            "display": true
          },
          {
            "label": "Scenarios",
            "name": "conditionAgentScenarios",
            "description": "Define the scenarios that will be used as the conditions to split the flow",
            "type": "array",
            "array": [
              {
                "label": "Scenario",
                "name": "scenario",
                "type": "string",
                "placeholder": "User is asking for a pizza"
              }
            ],
            "default": [
              {
                "scenario": "More subagents needed"
              },
              {
                "scenario": "Findings are sufficient"
              }
            ],
            "id": "conditionAgentAgentflow_0-input-conditionAgentScenarios-array",
            "display": true
          },
          {
            "label": "Override System Prompt",
            "name": "conditionAgentOverrideSystemPrompt",
            "type": "boolean",
            "description": "Override initial system prompt for Condition Agent",
            "optional": true,
            "id": "conditionAgentAgentflow_0-input-conditionAgentOverrideSystemPrompt-boolean",
            "display": true
          },
          {
            "label": "Node System Prompt",
            "name": "conditionAgentSystemPrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "default": "<p>You are part of a multi-agent system designed to make agent coordination and execution easy. Your task is to analyze the given input and select one matching scenario from a provided set of scenarios.</p><ul><li><strong>Input</strong>: A string representing the user's query, message or data.</li><li><strong>Scenarios</strong>: A list of predefined scenarios that relate to the input.</li><li><strong>Instruction</strong>: Determine which of the provided scenarios is the best fit for the input.</li></ul><h2>Steps</h2><ol><li><strong>Read the input string</strong> and the list of scenarios.</li><li><strong>Analyze the content of the input</strong> to identify its main topic or intention.</li><li><strong>Compare the input with each scenario</strong>: Evaluate how well the input's topic or intention aligns with each of the provided scenarios and select the one that is the best fit.</li><li><strong>Output the result</strong>: Return the selected scenario in the specified JSON format.</li></ol><h2>Output Format</h2><p>Output should be a JSON object that names the selected scenario, like this: <code>{\"output\": \"<selected_scenario_name>\"}</code>. No explanation is needed.</p><h2>Examples</h2><ol><li><p><strong>Input</strong>: <code>{\"input\": \"Hello\", \"scenarios\": [\"user is asking about AI\", \"user is not asking about AI\"], \"instruction\": \"Your task is to check if the user is asking about AI.\"}</code></p><p><strong>Output</strong>: <code>{\"output\": \"user is not asking about AI\"}</code></p></li><li><p><strong>Input</strong>: <code>{\"input\": \"What is AIGC?\", \"scenarios\": [\"user is asking about AI\", \"user is asking about the weather\"], \"instruction\": \"Your task is to check and see if the user is asking a topic about AI.\"}</code></p><p><strong>Output</strong>: <code>{\"output\": \"user is asking about AI\"}</code></p></li><li><p><strong>Input</strong>: <code>{\"input\": \"Can you explain deep learning?\", \"scenarios\": [\"user is interested in AI topics\", \"user wants to order food\"], \"instruction\": \"Determine if the user is interested in learning about AI.\"}</code></p><p><strong>Output</strong>: <code>{\"output\": \"user is interested in AI topics\"}</code></p></li></ol><h2>Note</h2><ul><li>Ensure that the input scenarios align well with potential user queries for accurate matching.</li><li>DO NOT include anything other than the JSON in your response.</li></ul>",
            "description": "Expert use only. Modifying this can significantly alter agent behavior. Leave default if unsure",
            "show": {
              "conditionAgentOverrideSystemPrompt": true
            },
            "id": "conditionAgentAgentflow_0-input-conditionAgentSystemPrompt-string",
            "display": false
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "conditionAgentModel": "chatLocalAI",
          "conditionAgentInstructions": "<p>Given a research topic, previous subagents and their findings, determine if more subagents are needed for further research or the findings are sufficient for the research topic</p>",
          "conditionAgentInput": "<p><research_topic>{{ $form.query }}</research_topic><subagents>{{ $flow.state.subagents }}</subagents><findings>{{ $flow.state.findings }}</findings><anonymize>{{ $form.anonymize }}</anonymize><output_type>{{ $form.output_type }}</output_type></p>",
          "conditionAgentScenarios": [
            {
              "scenario": "More subagents needed"
            },
            {
              "scenario": "Findings are sufficient"
            }
          ],
          "conditionAgentOverrideSystemPrompt": "",
          "conditionAgentModelConfig": {
            "credential": "",
            "modelName": "Qwen3-0.6B",
            "temperature": 0.7,
            "streaming": true,
            "maxTokensToSample": 512,
            "topP": "",
            "topK": "",
            "extendedThinking": "",
            "budgetTokens": 1024,
            "allowImageUploads": "",
            "conditionAgentModel": "chatLocalAI"
          }
        },
        "outputAnchors": [
          {
            "id": "conditionAgentAgentflow_0-output-0",
            "label": "Condition Agent",
            "name": "conditionAgentAgentflow"
          },
          {
            "id": "conditionAgentAgentflow_0-output-1",
            "label": "Condition Agent",
            "name": "conditionAgentAgentflow"
          }
        ],
        "outputs": {
          "conditionAgentAgentflow": ""
        },
        "selected": false
      },
      "type": "agentFlow",
      "width": 220,
      "height": 80,
      "selected": false,
      "positionAbsolute": {
        "x": 775.5108094609307,
        "y": 79.60273632963377
      },
      "dragging": false
    },
    {
      "id": "loopAgentflow_0",
      "position": {
        "x": 1041.3074957535728,
        "y": 20.713295322365383
      },
      "data": {
        "id": "loopAgentflow_0",
        "label": "Back to Planner",
        "version": 1,
        "name": "loopAgentflow",
        "type": "Loop",
        "color": "#FFA07A",
        "hideOutput": true,
        "baseClasses": [
          "Loop"
        ],
        "category": "Agent Flows",
        "description": "Loop back to a previous node",
        "inputParams": [
          {
            "label": "Loop Back To",
            "name": "loopBackToNode",
            "type": "asyncOptions",
            "loadMethod": "listPreviousNodes",
            "freeSolo": true,
            "id": "loopAgentflow_0-input-loopBackToNode-asyncOptions",
            "display": true
          },
          {
            "label": "Max Loop Count",
            "name": "maxLoopCount",
            "type": "number",
            "default": 5,
            "id": "loopAgentflow_0-input-maxLoopCount-number",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "loopBackToNode": "llmAgentflow_0-Planner",
          "maxLoopCount": "5"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 174,
      "height": 66,
      "selected": false,
      "positionAbsolute": {
        "x": 1041.3074957535728,
        "y": 20.713295322365383
      },
      "dragging": false
    },
    {
      "id": "directReplyAgentflow_0",
      "position": {
        "x": 1046.735958385286,
        "y": 140.25100072990062
      },
      "data": {
        "id": "directReplyAgentflow_0",
        "label": "Generate Report",
        "version": 1,
        "name": "directReplyAgentflow",
        "type": "DirectReply",
        "color": "#4DDBBB",
        "hideOutput": true,
        "baseClasses": [
          "DirectReply"
        ],
        "category": "Agent Flows",
        "description": "Directly reply to the user with a message",
        "inputParams": [
          {
            "label": "Message",
            "name": "directReplyMessage",
            "type": "string",
            "rows": 4,
            "acceptVariable": true,
            "id": "directReplyAgentflow_0-input-directReplyMessage-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "directReplyMessage": "<p>{{ $flow.state.findings }}</p>"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "type": "agentFlow",
      "width": 179,
      "height": 66,
      "positionAbsolute": {
        "x": 1046.735958385286,
        "y": 140.25100072990062
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "stickyNoteAgentflow_0",
      "position": {
        "x": 186.43721235573946,
        "y": -175.0715078328168
      },
      "data": {
        "id": "stickyNoteAgentflow_0",
        "label": "Sticky Note",
        "version": 1,
        "name": "stickyNoteAgentflow",
        "type": "StickyNote",
        "color": "#fee440",
        "baseClasses": [
          "StickyNote"
        ],
        "category": "Agent Flows",
        "description": "Add notes to the agent flow",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNoteAgentflow_0-input-note-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Each SubAgent has its own research task and tools to complete its findings for Biblical analysis"
        },
        "outputAnchors": [
          {
            "id": "stickyNoteAgentflow_0-output-stickyNoteAgentflow",
            "label": "Sticky Note",
            "name": "stickyNoteAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "stickyNote",
      "width": 221,
      "height": 123,
      "selected": false,
      "positionAbsolute": {
        "x": 186.43721235573946,
        "y": -175.0715078328168
      },
      "dragging": false
    },
    {
      "id": "stickyNoteAgentflow_1",
      "position": {
        "x": -117.00547059767304,
        "y": -24.08438212240118
      },
      "data": {
        "id": "stickyNoteAgentflow_1",
        "label": "Sticky Note (1)",
        "version": 1,
        "name": "stickyNoteAgentflow",
        "type": "StickyNote",
        "color": "#fee440",
        "baseClasses": [
          "StickyNote"
        ],
        "category": "Agent Flows",
        "description": "Add notes to the agent flow",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNoteAgentflow_1-input-note-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Planner will generate list of subagents for Biblical forensic analysis"
        },
        "outputAnchors": [
          {
            "id": "stickyNoteAgentflow_1-output-stickyNoteAgentflow",
            "label": "Sticky Note",
            "name": "stickyNoteAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "stickyNote",
      "width": 221,
      "height": 82,
      "selected": false,
      "positionAbsolute": {
        "x": -117.00547059767304,
        "y": -24.08438212240118
      },
      "dragging": false
    },
    {
      "id": "stickyNoteAgentflow_3",
      "position": {
        "x": 494.1635881448354,
        "y": -47.5842428829507
      },
      "data": {
        "id": "stickyNoteAgentflow_3",
        "label": "Sticky Note (3)",
        "version": 1,
        "name": "stickyNoteAgentflow",
        "type": "StickyNote",
        "color": "#fee440",
        "baseClasses": [
          "StickyNote"
        ],
        "category": "Agent Flows",
        "description": "Add notes to the agent flow",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNoteAgentflow_3-input-note-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "Writer Agent combines findings and generates a report with Biblical insights"
        },
        "outputAnchors": [
          {
            "id": "stickyNoteAgentflow_3-output-stickyNoteAgentflow",
            "label": "Sticky Note",
            "name": "stickyNoteAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "type": "stickyNote",
      "width": 221,
      "height": 102,
      "selected": false,
      "positionAbsolute": {
        "x": 494.1635881448354,
        "y": -47.5842428829507
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "startAgentflow_0",
      "sourceHandle": "startAgentflow_0-output-startAgentflow",
      "target": "llmAgentflow_0",
      "targetHandle": "llmAgentflow_0",
      "data": {
        "sourceColor": "#7EE787",
        "targetColor": "#64B5F6",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "startAgentflow_0-startAgentflow_0-output-startAgentflow-llmAgentflow_0-llmAgentflow_0"
    },
    {
      "source": "chatLocalAI_0",
      "sourceHandle": "chatLocalAI_0-output-chatLocalAI",
      "target": "llmAgentflow_0",
      "targetHandle": "llmAgentflow_0",
      "data": {
        "sourceColor": "#FF6347",
        "targetColor": "#64B5F6",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "chatLocalAI_0-chatLocalAI_0-output-chatLocalAI-llmAgentflow_0-llmAgentflow_0"
    },
    {
      "source": "llmAgentflow_0",
      "sourceHandle": "llmAgentflow_0-output-llmAgentflow",
      "target": "iterationAgentflow_0",
      "targetHandle": "iterationAgentflow_0",
      "data": {
        "sourceColor": "#64B5F6",
        "targetColor": "#9C89B8",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "llmAgentflow_0-llmAgentflow_0-output-llmAgentflow-iterationAgentflow_0-iterationAgentflow_0"
    },
    {
      "source": "iterationAgentflow_0",
      "sourceHandle": "iterationAgentflow_0-output-iterationAgentflow",
      "target": "agentAgentflow_1",
      "targetHandle": "agentAgentflow_1",
      "data": {
        "sourceColor": "#9C89B8",
        "targetColor": "#4DD0E1",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "iterationAgentflow_0-iterationAgentflow_0-output-iterationAgentflow-agentAgentflow_1-agentAgentflow_1"
    },
    {
      "source": "agentAgentflow_1",
      "sourceHandle": "agentAgentflow_1-output-agentAgentflow",
      "target": "conditionAgentAgentflow_0",
      "targetHandle": "conditionAgentAgentflow_0",
      "data": {
        "sourceColor": "#4DD0E1",
        "targetColor": "#ff8fab",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "agentAgentflow_1-agentAgentflow_1-output-agentAgentflow-conditionAgentAgentflow_0-conditionAgentAgentflow_0"
    },
    {
      "source": "conditionAgentAgentflow_0",
      "sourceHandle": "conditionAgentAgentflow_0-output-0",
      "target": "loopAgentflow_0",
      "targetHandle": "loopAgentflow_0",
      "data": {
        "sourceColor": "#ff8fab",
        "targetColor": "#FFA07A",
        "edgeLabel": "0",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentAgentflow_0-conditionAgentAgentflow_0-output-0-loopAgentflow_0-loopAgentflow_0"
    },
    {
      "source": "conditionAgentAgentflow_0",
      "sourceHandle": "conditionAgentAgentflow_0-output-1",
      "target": "directReplyAgentflow_0",
      "targetHandle": "directReplyAgentflow_0",
      "data": {
        "sourceColor": "#ff8fab",
        "targetColor": "#4DDBBB",
        "edgeLabel": "1",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentAgentflow_0-conditionAgentAgentflow_0-output-1-directReplyAgentflow_0-directReplyAgentflow_0"
    }
  ]
}